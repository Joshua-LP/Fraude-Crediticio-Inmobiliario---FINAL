{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba1028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerias cargadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, precision_score, \n",
    "    recall_score, accuracy_score, classification_report\n",
    ")\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.semi_supervised import LabelSpreading, SelfTrainingClassifier\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Librerias cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce9eeae",
   "metadata": {},
   "source": [
    "## Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a8a3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados: (307511, 122)\n",
      "Tasa de fraude: 8.07%\n"
     ]
    }
   ],
   "source": [
    "ruta_datos = os.path.join(os.getcwd(), \"data\", \"data\", \"application_train.csv\")\n",
    "\n",
    "if not os.path.exists(ruta_datos):\n",
    "    print(f\"Error: No se encuentra el archivo {ruta_datos}\")\n",
    "else:\n",
    "    datos = pd.read_csv(ruta_datos)\n",
    "    print(f\"Datos cargados: {datos.shape}\")\n",
    "    print(f\"Tasa de fraude: {datos['TARGET'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d916093",
   "metadata": {},
   "source": [
    "## Resultados de Evaluaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13effa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103c0ba9",
   "metadata": {},
   "source": [
    "### 1. Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163ad1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Evaluando Autoencoder ---\n",
      "Datos preparados - Train: (226148, 13), Val: (56538, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Evaluando Autoencoder ---\")\n",
    "\n",
    "# Variables de tiempo\n",
    "datos['EDAD'] = -datos['DAYS_BIRTH'] / 365\n",
    "datos['ANOS_EMPLEADO'] = -datos['DAYS_EMPLOYED'] / 365\n",
    "datos['ANOS_EMPLEADO'] = datos['ANOS_EMPLEADO'].replace(1000.67, np.nan)\n",
    "\n",
    "# Ratios financieros\n",
    "datos['RATIO_CREDITO_INGRESO'] = datos['AMT_CREDIT'] / datos['AMT_INCOME_TOTAL']\n",
    "datos['RATIO_ANUALIDAD_INGRESO'] = datos['AMT_ANNUITY'] / datos['AMT_INCOME_TOTAL']\n",
    "datos['INGRESO_PER_CAPITA'] = datos['AMT_INCOME_TOTAL'] / (datos['CNT_FAM_MEMBERS'] + 1)\n",
    "\n",
    "# Variables de inconsistencia\n",
    "datos['INCONS_SCORE_INGRESO'] = 0\n",
    "mask1 = (datos['EXT_SOURCE_2'] < 0.3) & (datos['AMT_INCOME_TOTAL'] > datos['AMT_INCOME_TOTAL'].quantile(0.75))\n",
    "datos.loc[mask1, 'INCONS_SCORE_INGRESO'] = 1\n",
    "\n",
    "variables = [\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY',\n",
    "    'RATIO_CREDITO_INGRESO', 'RATIO_ANUALIDAD_INGRESO',\n",
    "    'INGRESO_PER_CAPITA', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "    'EDAD', 'ANOS_EMPLEADO', 'CNT_CHILDREN', 'CNT_FAM_MEMBERS',\n",
    "    'INCONS_SCORE_INGRESO'\n",
    "]\n",
    "\n",
    "datos_trabajo = datos[variables + ['TARGET']].copy()\n",
    "\n",
    "for col in variables:\n",
    "    if datos_trabajo[col].isnull().sum() > 0:\n",
    "        datos_trabajo[col].fillna(datos_trabajo[col].median(), inplace=True)\n",
    "\n",
    "X = datos_trabajo[variables].values\n",
    "y = datos_trabajo['TARGET'].values\n",
    "\n",
    "# Separar datos normales\n",
    "mascara_normal = y == 0\n",
    "X_normales = X[mascara_normal]\n",
    "\n",
    "X_train, X_val = train_test_split(X_normales, test_size=0.2, random_state=42)\n",
    "\n",
    "escalador = RobustScaler()\n",
    "X_train_esc = escalador.fit_transform(X_train)\n",
    "X_val_esc = escalador.transform(X_val)\n",
    "X_todos_esc = escalador.transform(X)\n",
    "\n",
    "print(f\"Datos preparados - Train: {X_train.shape}, Val: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2600dd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando autoencoder...\n",
      "Epoch 1/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - loss: 1.3689 - val_loss: 0.2686\n",
      "Epoch 2/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.2343 - val_loss: 0.1538\n",
      "Epoch 3/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.1856 - val_loss: 0.1104\n",
      "Epoch 4/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 0.1748 - val_loss: 0.1220\n",
      "Epoch 5/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.1660 - val_loss: 0.1032\n",
      "Epoch 6/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.1585 - val_loss: 0.1099\n",
      "Epoch 7/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 0.1547 - val_loss: 0.1029\n",
      "Epoch 8/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 0.1461 - val_loss: 0.1138\n",
      "Epoch 9/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.1453 - val_loss: 0.1038\n",
      "Epoch 10/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.1424 - val_loss: 0.0848\n",
      "Epoch 11/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.1384 - val_loss: 0.0971\n",
      "Epoch 12/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.1383 - val_loss: 0.1006\n",
      "Epoch 13/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.1352 - val_loss: 0.0926\n",
      "Epoch 14/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 0.1344 - val_loss: 0.0884\n",
      "Epoch 15/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.1314 - val_loss: 0.1353\n",
      "Epoch 16/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.1331 - val_loss: 0.0881\n",
      "Epoch 17/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 0.1271 - val_loss: 0.0896\n",
      "Epoch 18/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 0.1286 - val_loss: 0.0937\n",
      "Epoch 19/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - loss: 0.1298 - val_loss: 0.1036\n",
      "Epoch 20/50\n",
      "\u001b[1m884/884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 0.1249 - val_loss: 0.1019\n",
      "Entrenamiento completado\n"
     ]
    }
   ],
   "source": [
    "# Arquitectura del autoencoder\n",
    "dim_entrada = X_train_esc.shape[1]\n",
    "entrada = Input(shape=(dim_entrada,))\n",
    "\n",
    "x = Dense(64, activation='relu')(entrada)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "codigo = Dense(16, activation='relu')(x)\n",
    "\n",
    "x = Dense(32, activation='relu')(codigo)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(64, activation='relu')(x)\n",
    "salida = Dense(dim_entrada, activation='linear')(x)\n",
    "\n",
    "autoencoder = Model(entrada, salida)\n",
    "autoencoder.compile(optimizer='adam', loss='mae')\n",
    "\n",
    "parada = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)\n",
    "\n",
    "print(\"Entrenando autoencoder...\")\n",
    "autoencoder.fit(\n",
    "    X_train_esc, X_train_esc,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val_esc, X_val_esc),\n",
    "    callbacks=[parada],\n",
    "    verbose=1\n",
    ")\n",
    "print(\"Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2fb1db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.4792\n",
      "F1-Score: 0.0835\n",
      "Precision: 0.0643\n",
      "Recall: 0.1194\n"
     ]
    }
   ],
   "source": [
    "# Calcular errores de reconstruccion\n",
    "X_reconstruido = autoencoder.predict(X_todos_esc, verbose=0)\n",
    "error_reconstruccion = np.mean(np.abs(X_todos_esc - X_reconstruido), axis=1)\n",
    "\n",
    "# Optimizar umbral\n",
    "umbrales = np.percentile(error_reconstruccion, range(85, 100, 1))\n",
    "mejor_f1 = 0\n",
    "mejor_umbral = 0\n",
    "\n",
    "for umbral in umbrales:\n",
    "    predicciones = (error_reconstruccion > umbral).astype(int)\n",
    "    f1 = f1_score(y, predicciones, zero_division=0)\n",
    "    if f1 > mejor_f1:\n",
    "        mejor_f1 = f1\n",
    "        mejor_umbral = umbral\n",
    "\n",
    "predicciones_finales = (error_reconstruccion > mejor_umbral).astype(int)\n",
    "\n",
    "# Metricas\n",
    "metricas_ae = {\n",
    "    'modelo': 'Autoencoder',\n",
    "    'accuracy': accuracy_score(y, predicciones_finales),\n",
    "    'precision': precision_score(y, predicciones_finales, zero_division=0),\n",
    "    'recall': recall_score(y, predicciones_finales, zero_division=0),\n",
    "    'f1_score': f1_score(y, predicciones_finales, zero_division=0),\n",
    "    'roc_auc': roc_auc_score(y, error_reconstruccion)\n",
    "}\n",
    "\n",
    "resultados.append(metricas_ae)\n",
    "print(f\"AUC-ROC: {metricas_ae['roc_auc']:.4f}\")\n",
    "print(f\"F1-Score: {metricas_ae['f1_score']:.4f}\")\n",
    "print(f\"Precision: {metricas_ae['precision']:.4f}\")\n",
    "print(f\"Recall: {metricas_ae['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aea304b",
   "metadata": {},
   "source": [
    "### 2. Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66ea476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluando Isolation Forest ---\n",
      "Entrenando con muestra de 10000 registros...\n",
      "AUC-ROC: 0.4590\n",
      "F1-Score: 0.0590\n",
      "Precision: 0.0612\n",
      "Recall: 0.0570\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluando Isolation Forest ---\")\n",
    "\n",
    "columnas_numericas = datos.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if 'SK_ID_CURR' in columnas_numericas:\n",
    "    columnas_numericas.remove('SK_ID_CURR')\n",
    "if 'TARGET' in columnas_numericas:\n",
    "    columnas_numericas.remove('TARGET')\n",
    "    \n",
    "datos_num = datos[columnas_numericas].fillna(datos[columnas_numericas].median())\n",
    "X_if = datos_num.values\n",
    "y_if = datos['TARGET'].values\n",
    "\n",
    "# Tomar muestra\n",
    "muestra_size = min(10000, len(X_if))\n",
    "indices = np.random.choice(len(X_if), muestra_size, replace=False)\n",
    "X_muestra = X_if[indices]\n",
    "y_muestra = y_if[indices]\n",
    "\n",
    "modelo_if = IsolationForest(\n",
    "    contamination=0.08,\n",
    "    random_state=42,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "print(f\"Entrenando con muestra de {muestra_size} registros...\")\n",
    "predicciones = modelo_if.fit_predict(X_muestra)\n",
    "predicciones = (predicciones == -1).astype(int)\n",
    "\n",
    "scores = modelo_if.score_samples(X_muestra)\n",
    "\n",
    "# Metricas\n",
    "metricas_if = {\n",
    "    'modelo': 'Isolation Forest',\n",
    "    'accuracy': accuracy_score(y_muestra, predicciones),\n",
    "    'precision': precision_score(y_muestra, predicciones, zero_division=0),\n",
    "    'recall': recall_score(y_muestra, predicciones, zero_division=0),\n",
    "    'f1_score': f1_score(y_muestra, predicciones, zero_division=0),\n",
    "    'roc_auc': roc_auc_score(y_muestra, -scores)\n",
    "}\n",
    "\n",
    "resultados.append(metricas_if)\n",
    "print(f\"AUC-ROC: {metricas_if['roc_auc']:.4f}\")\n",
    "print(f\"F1-Score: {metricas_if['f1_score']:.4f}\")\n",
    "print(f\"Precision: {metricas_if['precision']:.4f}\")\n",
    "print(f\"Recall: {metricas_if['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde42a00",
   "metadata": {},
   "source": [
    "### 3. LOF (Local Outlier Factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0109a661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluando LOF ---\n",
      "Entrenando con muestra de 5000 registros...\n",
      "AUC-ROC: 0.5051\n",
      "F1-Score: 0.0941\n",
      "Precision: 0.0925\n",
      "Recall: 0.0959\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluando LOF ---\")\n",
    "\n",
    "# Tomar muestra\n",
    "muestra_size = min(5000, len(X_if))\n",
    "indices = np.random.choice(len(X_if), muestra_size, replace=False)\n",
    "X_muestra_lof = X_if[indices]\n",
    "y_muestra_lof = y_if[indices]\n",
    "\n",
    "modelo_lof = LocalOutlierFactor(\n",
    "    n_neighbors=20,\n",
    "    contamination=0.08,\n",
    "    novelty=False\n",
    ")\n",
    "\n",
    "print(f\"Entrenando con muestra de {muestra_size} registros...\")\n",
    "predicciones_lof = modelo_lof.fit_predict(X_muestra_lof)\n",
    "predicciones_lof = (predicciones_lof == -1).astype(int)\n",
    "\n",
    "scores_lof = modelo_lof.negative_outlier_factor_\n",
    "\n",
    "# Metricas\n",
    "metricas_lof = {\n",
    "    'modelo': 'LOF',\n",
    "    'accuracy': accuracy_score(y_muestra_lof, predicciones_lof),\n",
    "    'precision': precision_score(y_muestra_lof, predicciones_lof, zero_division=0),\n",
    "    'recall': recall_score(y_muestra_lof, predicciones_lof, zero_division=0),\n",
    "    'f1_score': f1_score(y_muestra_lof, predicciones_lof, zero_division=0),\n",
    "    'roc_auc': roc_auc_score(y_muestra_lof, -scores_lof)\n",
    "}\n",
    "\n",
    "resultados.append(metricas_lof)\n",
    "print(f\"AUC-ROC: {metricas_lof['roc_auc']:.4f}\")\n",
    "print(f\"F1-Score: {metricas_lof['f1_score']:.4f}\")\n",
    "print(f\"Precision: {metricas_lof['precision']:.4f}\")\n",
    "print(f\"Recall: {metricas_lof['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d4007",
   "metadata": {},
   "source": [
    "### 4. Self-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55dd2dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluando Self-Training ---\n",
      "Datos etiquetados: 24600 (10%)\n",
      "Entrenando modelo Self-Training...\n",
      "AUC-ROC: 0.7092\n",
      "F1-Score: 0.0012\n",
      "Precision: 0.7500\n",
      "Recall: 0.0006\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluando Self-Training ---\")\n",
    "\n",
    "columnas_num = ['CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', \n",
    "                'AMT_ANNUITY', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
    "                'EXT_SOURCE_2', 'EXT_SOURCE_3']\n",
    "\n",
    "datos_num_st = datos[columnas_num + ['TARGET']].copy()\n",
    "datos_num_st = datos_num_st.fillna(datos_num_st.median())\n",
    "\n",
    "X_st = datos_num_st.drop('TARGET', axis=1).values\n",
    "y_st = datos_num_st['TARGET'].values\n",
    "\n",
    "X_train_st, X_test_st, y_train_st, y_test_st = train_test_split(\n",
    "    X_st, y_st, test_size=0.2, random_state=42, stratify=y_st\n",
    ")\n",
    "\n",
    "# Simular datos sin etiquetas\n",
    "porcentaje_etiquetado = 0.1\n",
    "n_etiquetados = int(len(X_train_st) * porcentaje_etiquetado)\n",
    "\n",
    "y_train_semi = y_train_st.copy()\n",
    "indices_sin_etiquetar = np.random.choice(\n",
    "    range(n_etiquetados, len(y_train_st)),\n",
    "    size=len(y_train_st) - n_etiquetados,\n",
    "    replace=False\n",
    ")\n",
    "y_train_semi[indices_sin_etiquetar] = -1\n",
    "\n",
    "escalador_st = StandardScaler()\n",
    "X_train_esc_st = escalador_st.fit_transform(X_train_st)\n",
    "X_test_esc_st = escalador_st.transform(X_test_st)\n",
    "\n",
    "print(f\"Datos etiquetados: {n_etiquetados} ({porcentaje_etiquetado*100:.0f}%)\")\n",
    "print(\"Entrenando modelo Self-Training...\")\n",
    "\n",
    "modelo_base_st = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=10)\n",
    "modelo_st = SelfTrainingClassifier(modelo_base_st, threshold=0.9, max_iter=10, verbose=False)\n",
    "\n",
    "modelo_st.fit(X_train_esc_st, y_train_semi)\n",
    "predicciones_st = modelo_st.predict(X_test_esc_st)\n",
    "predicciones_proba_st = modelo_st.predict_proba(X_test_esc_st)[:, 1]\n",
    "\n",
    "# Metricas\n",
    "metricas_st = {\n",
    "    'modelo': 'Self-Training',\n",
    "    'accuracy': accuracy_score(y_test_st, predicciones_st),\n",
    "    'precision': precision_score(y_test_st, predicciones_st, zero_division=0),\n",
    "    'recall': recall_score(y_test_st, predicciones_st, zero_division=0),\n",
    "    'f1_score': f1_score(y_test_st, predicciones_st, zero_division=0),\n",
    "    'roc_auc': roc_auc_score(y_test_st, predicciones_proba_st)\n",
    "}\n",
    "\n",
    "resultados.append(metricas_st)\n",
    "print(f\"AUC-ROC: {metricas_st['roc_auc']:.4f}\")\n",
    "print(f\"F1-Score: {metricas_st['f1_score']:.4f}\")\n",
    "print(f\"Precision: {metricas_st['precision']:.4f}\")\n",
    "print(f\"Recall: {metricas_st['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d710c112",
   "metadata": {},
   "source": [
    "### 5. Label Spreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a5134d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluando Label Spreading ---\n",
      "Muestra: 5000 registros\n",
      "Datos etiquetados: 400 (10%)\n",
      "Entrenando modelo Label Spreading...\n",
      "AUC-ROC: 0.5348\n",
      "F1-Score: 0.0839\n",
      "Precision: 0.0952\n",
      "Recall: 0.0750\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Evaluando Label Spreading ---\")\n",
    "\n",
    "columnas_num_ls = ['CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT',\n",
    "                   'AMT_ANNUITY', 'DAYS_BIRTH', 'DAYS_EMPLOYED',\n",
    "                   'EXT_SOURCE_2', 'EXT_SOURCE_3']\n",
    "\n",
    "datos_num_ls = datos[columnas_num_ls + ['TARGET']].copy()\n",
    "datos_num_ls = datos_num_ls.fillna(datos_num_ls.median())\n",
    "\n",
    "X_ls = datos_num_ls.drop('TARGET', axis=1).values\n",
    "y_ls = datos_num_ls['TARGET'].values\n",
    "\n",
    "# Tomar muestra\n",
    "muestra_size_ls = min(5000, len(X_ls))\n",
    "indices_ls = np.random.choice(len(X_ls), muestra_size_ls, replace=False)\n",
    "X_muestra_ls = X_ls[indices_ls]\n",
    "y_muestra_ls = y_ls[indices_ls]\n",
    "\n",
    "X_train_ls, X_test_ls, y_train_ls, y_test_ls = train_test_split(\n",
    "    X_muestra_ls, y_muestra_ls, test_size=0.2, random_state=42, stratify=y_muestra_ls\n",
    ")\n",
    "\n",
    "# Simular datos sin etiquetas\n",
    "porcentaje_etiquetado_ls = 0.1\n",
    "n_etiquetados_ls = int(len(X_train_ls) * porcentaje_etiquetado_ls)\n",
    "\n",
    "y_train_semi_ls = y_train_ls.copy()\n",
    "indices_sin_etiquetar_ls = np.random.choice(\n",
    "    range(n_etiquetados_ls, len(y_train_ls)),\n",
    "    size=len(y_train_ls) - n_etiquetados_ls,\n",
    "    replace=False\n",
    ")\n",
    "y_train_semi_ls[indices_sin_etiquetar_ls] = -1\n",
    "\n",
    "escalador_ls = StandardScaler()\n",
    "X_train_esc_ls = escalador_ls.fit_transform(X_train_ls)\n",
    "X_test_esc_ls = escalador_ls.transform(X_test_ls)\n",
    "\n",
    "print(f\"Muestra: {muestra_size_ls} registros\")\n",
    "print(f\"Datos etiquetados: {n_etiquetados_ls} ({porcentaje_etiquetado_ls*100:.0f}%)\")\n",
    "print(\"Entrenando modelo Label Spreading...\")\n",
    "\n",
    "modelo_ls = LabelSpreading(kernel='rbf', alpha=0.2, max_iter=30)\n",
    "modelo_ls.fit(X_train_esc_ls, y_train_semi_ls)\n",
    "\n",
    "predicciones_ls = modelo_ls.predict(X_test_esc_ls)\n",
    "predicciones_proba_ls = modelo_ls.predict_proba(X_test_esc_ls)[:, 1]\n",
    "\n",
    "# Metricas\n",
    "metricas_ls = {\n",
    "    'modelo': 'Label Spreading',\n",
    "    'accuracy': accuracy_score(y_test_ls, predicciones_ls),\n",
    "    'precision': precision_score(y_test_ls, predicciones_ls, zero_division=0),\n",
    "    'recall': recall_score(y_test_ls, predicciones_ls, zero_division=0),\n",
    "    'f1_score': f1_score(y_test_ls, predicciones_ls, zero_division=0),\n",
    "    'roc_auc': roc_auc_score(y_test_ls, predicciones_proba_ls)\n",
    "}\n",
    "\n",
    "resultados.append(metricas_ls)\n",
    "print(f\"AUC-ROC: {metricas_ls['roc_auc']:.4f}\")\n",
    "print(f\"F1-Score: {metricas_ls['f1_score']:.4f}\")\n",
    "print(f\"Precision: {metricas_ls['precision']:.4f}\")\n",
    "print(f\"Recall: {metricas_ls['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3d523c",
   "metadata": {},
   "source": [
    "## Comparacion Final de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a55a694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARACION DE MODELOS - DETECCION DE FRAUDE\n",
      "================================================================================\n",
      "          modelo  accuracy  precision   recall  f1_score  roc_auc\n",
      "     Autoencoder  0.788547   0.064257 0.119396  0.083549 0.479229\n",
      "Isolation Forest  0.843800   0.061250 0.056977  0.059036 0.459046\n",
      "             LOF  0.857600   0.092500 0.095855  0.094148 0.505083\n",
      "   Self-Training  0.919305   0.750000 0.000604  0.001207 0.709237\n",
      " Label Spreading  0.869000   0.095238 0.075000  0.083916 0.534837\n"
     ]
    }
   ],
   "source": [
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARACION DE MODELOS - DETECCION DE FRAUDE\")\n",
    "print(\"=\"*80)\n",
    "print(df_resultados.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e24e7317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MEJOR MODELO POR METRICA\n",
      "================================================================================\n",
      "ACCURACY       : Self-Training        (0.9193)\n",
      "PRECISION      : Self-Training        (0.7500)\n",
      "RECALL         : Autoencoder          (0.1194)\n",
      "F1_SCORE       : LOF                  (0.0941)\n",
      "ROC_AUC        : Self-Training        (0.7092)\n"
     ]
    }
   ],
   "source": [
    "# Identificar mejor modelo por metrica\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MEJOR MODELO POR METRICA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for metrica in ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc']:\n",
    "    mejor_idx = df_resultados[metrica].idxmax()\n",
    "    mejor_modelo = df_resultados.loc[mejor_idx, 'modelo']\n",
    "    mejor_valor = df_resultados.loc[mejor_idx, metrica]\n",
    "    print(f\"{metrica.upper():15s}: {mejor_modelo:20s} ({mejor_valor:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61709705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RANKING GENERAL (menor es mejor)\n",
      "================================================================================\n",
      " 2. Label Spreading      (Promedio: 2.20)\n",
      " 2. LOF                  (Promedio: 2.40)\n",
      " 2. Self-Training        (Promedio: 2.60)\n",
      " 3. Autoencoder          (Promedio: 3.40)\n",
      " 4. Isolation Forest     (Promedio: 4.40)\n"
     ]
    }
   ],
   "source": [
    "# Ranking general\n",
    "df_rank = df_resultados.copy()\n",
    "for col in ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc']:\n",
    "    df_rank[f'rank_{col}'] = df_rank[col].rank(ascending=False)\n",
    "\n",
    "df_rank['ranking_promedio'] = df_rank[[f'rank_{col}' for col in ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc']]].mean(axis=1)\n",
    "df_rank = df_rank.sort_values('ranking_promedio')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANKING GENERAL (menor es mejor)\")\n",
    "print(\"=\"*80)\n",
    "for idx, row in df_rank.iterrows():\n",
    "    print(f\"{int(row['ranking_promedio']):2d}. {row['modelo']:20s} (Promedio: {row['ranking_promedio']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8ca42fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados exportados a: comparacion_modelos.csv\n"
     ]
    }
   ],
   "source": [
    "# Exportar resultados\n",
    "df_resultados.to_csv('comparacion_modelos.csv', index=False)\n",
    "print(\"\\nResultados exportados a: comparacion_modelos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39d114e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Autoencoder</td>\n",
       "      <td>0.788547</td>\n",
       "      <td>0.064257</td>\n",
       "      <td>0.119396</td>\n",
       "      <td>0.083549</td>\n",
       "      <td>0.479229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Isolation Forest</td>\n",
       "      <td>0.843800</td>\n",
       "      <td>0.061250</td>\n",
       "      <td>0.056977</td>\n",
       "      <td>0.059036</td>\n",
       "      <td>0.459046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOF</td>\n",
       "      <td>0.857600</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.095855</td>\n",
       "      <td>0.094148</td>\n",
       "      <td>0.505083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Self-Training</td>\n",
       "      <td>0.919305</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.709237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Label Spreading</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.083916</td>\n",
       "      <td>0.534837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             modelo  accuracy  precision    recall  f1_score   roc_auc\n",
       "0       Autoencoder  0.788547   0.064257  0.119396  0.083549  0.479229\n",
       "1  Isolation Forest  0.843800   0.061250  0.056977  0.059036  0.459046\n",
       "2               LOF  0.857600   0.092500  0.095855  0.094148  0.505083\n",
       "3     Self-Training  0.919305   0.750000  0.000604  0.001207  0.709237\n",
       "4   Label Spreading  0.869000   0.095238  0.075000  0.083916  0.534837"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar tabla final formateada\n",
    "df_resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
