{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SISTEMA HÍBRIDO DE DETECCIÓN DE FRAUDE CREDITICIO\n",
    "### Integración Optimizada: Isolation Forest + Autoencoder + LSTM + Semi-Supervisado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 1: IMPORTAR LIBRERÍAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías cargadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, f1_score, precision_score, recall_score,\n",
    "    accuracy_score, average_precision_score\n",
    ")\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, RepeatVector, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print(\"Librerías cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 2: CARGAR DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INFORMACIÓN DEL DATASET\n",
      "================================================================================\n",
      "Registros: 307,511\n",
      "Variables: 122\n",
      "\n",
      "Distribución TARGET:\n",
      "  Normal (0): 282,686 (91.93%)\n",
      "  Fraude (1): 24,825 (8.07%)\n",
      "\n",
      "Usando muestra estratificada: 50,000 registros\n"
     ]
    }
   ],
   "source": [
    "ruta_datos = \"data/data/application_train.csv\"\n",
    "datos = pd.read_csv(ruta_datos)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INFORMACIÓN DEL DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Registros: {len(datos):,}\")\n",
    "print(f\"Variables: {datos.shape[1]}\")\n",
    "print(f\"\\nDistribución TARGET:\")\n",
    "print(f\"  Normal (0): {(datos['TARGET']==0).sum():,} ({(datos['TARGET']==0).mean()*100:.2f}%)\")\n",
    "print(f\"  Fraude (1): {(datos['TARGET']==1).sum():,} ({(datos['TARGET']==1).mean()*100:.2f}%)\")\n",
    "\n",
    "# Usar muestra estratificada para acelerar desarrollo\n",
    "TAMAÑO_MUESTRA = 50000\n",
    "if len(datos) > TAMAÑO_MUESTRA:\n",
    "    datos, _ = train_test_split(datos, train_size=TAMAÑO_MUESTRA, random_state=42, stratify=datos['TARGET'])\n",
    "    print(f\"\\nUsando muestra estratificada: {TAMAÑO_MUESTRA:,} registros\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
