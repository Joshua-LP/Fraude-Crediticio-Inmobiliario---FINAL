{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SISTEMA HÍBRIDO DE DETECCIÓN DE FRAUDE CREDITICIO\n",
    "### Integración Optimizada: Isolation Forest + Autoencoder + LSTM + Semi-Supervisado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 1: IMPORTAR LIBRERÍAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías cargadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, f1_score, precision_score, recall_score,\n",
    "    accuracy_score, average_precision_score\n",
    ")\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, RepeatVector, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "print(\"Librerías cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 2: CARGAR DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INFORMACIÓN DEL DATASET\n",
      "================================================================================\n",
      "Registros: 307,511\n",
      "Variables: 122\n",
      "\n",
      "Distribución TARGET:\n",
      "  Normal (0): 282,686 (91.93%)\n",
      "  Fraude (1): 24,825 (8.07%)\n",
      "\n",
      "Usando muestra estratificada: 50,000 registros\n"
     ]
    }
   ],
   "source": [
    "ruta_datos = \"data/data/application_train.csv\"\n",
    "datos = pd.read_csv(ruta_datos)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"INFORMACIÓN DEL DATASET\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Registros: {len(datos):,}\")\n",
    "print(f\"Variables: {datos.shape[1]}\")\n",
    "print(f\"\\nDistribución TARGET:\")\n",
    "print(f\"  Normal (0): {(datos['TARGET']==0).sum():,} ({(datos['TARGET']==0).mean()*100:.2f}%)\")\n",
    "print(f\"  Fraude (1): {(datos['TARGET']==1).sum():,} ({(datos['TARGET']==1).mean()*100:.2f}%)\")\n",
    "\n",
    "# Usar muestra estratificada para acelerar desarrollo\n",
    "TAMAÑO_MUESTRA = 50000\n",
    "if len(datos) > TAMAÑO_MUESTRA:\n",
    "    datos, _ = train_test_split(datos, train_size=TAMAÑO_MUESTRA, random_state=42, stratify=datos['TARGET'])\n",
    "    print(f\"\\nUsando muestra estratificada: {TAMAÑO_MUESTRA:,} registros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 3: FEATURE ENGINEERING AVANZADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE ENGINEERING\n",
      "================================================================================\n",
      "Feature Engineering completado\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df = datos.copy()\n",
    "\n",
    "# Variables temporales\n",
    "df['edad'] = -df['DAYS_BIRTH'] / 365\n",
    "df['años_empleado'] = -df['DAYS_EMPLOYED'] / 365\n",
    "df['años_empleado'] = df['años_empleado'].replace(1000.67, np.nan)\n",
    "df['dias_registro'] = -df['DAYS_REGISTRATION']\n",
    "df['dias_id_publicacion'] = -df['DAYS_ID_PUBLISH']\n",
    "\n",
    "# Ratios financieros clave\n",
    "df['ratio_credito_ingreso'] = df['AMT_CREDIT'] / (df['AMT_INCOME_TOTAL'] + 1)\n",
    "df['ratio_anualidad_ingreso'] = df['AMT_ANNUITY'] / (df['AMT_INCOME_TOTAL'] + 1)\n",
    "df['ratio_anualidad_credito'] = df['AMT_ANNUITY'] / (df['AMT_CREDIT'] + 1)\n",
    "df['ratio_bienes_credito'] = df['AMT_GOODS_PRICE'] / (df['AMT_CREDIT'] + 1)\n",
    "\n",
    "# Variables per capita\n",
    "df['ingreso_per_capita'] = df['AMT_INCOME_TOTAL'] / (df['CNT_FAM_MEMBERS'] + 1)\n",
    "df['credito_per_capita'] = df['AMT_CREDIT'] / (df['CNT_FAM_MEMBERS'] + 1)\n",
    "\n",
    "# Indicadores de riesgo\n",
    "df['ratio_edad_empleo'] = df['años_empleado'] / (df['edad'] + 1)\n",
    "df['tiene_telefono'] = df['FLAG_MOBIL'].fillna(0)\n",
    "df['tiene_email'] = df['FLAG_EMAIL'].fillna(0)\n",
    "df['tiene_trabajo_telefono'] = df['FLAG_WORK_PHONE'].fillna(0)\n",
    "\n",
    "# Inconsistencias lógicas (señales de fraude)\n",
    "df['inconsistencia_empleo_edad'] = (df['años_empleado'] > df['edad']).astype(int)\n",
    "df['inconsistencia_ingreso_alto'] = ((df['AMT_INCOME_TOTAL'] > 500000) & (df['REGION_RATING_CLIENT'] == 3)).astype(int)\n",
    "\n",
    "# Codificar categóricas importantes\n",
    "variables_categoricas = [\n",
    "    'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
    "    'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE'\n",
    "]\n",
    "\n",
    "label_encoders = {}\n",
    "for col in variables_categoricas:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = df[col].fillna('Desconocido')\n",
    "        df[f'{col}_cod'] = le.fit_transform(df[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "print(\"Feature Engineering completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 4: SELECCIÓN Y PREPARACIÓN DE VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables finales: 37\n",
      "Nulos restantes: 0\n"
     ]
    }
   ],
   "source": [
    "variables_numericas = [\n",
    "    'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE',\n",
    "    'ratio_credito_ingreso', 'ratio_anualidad_ingreso', 'ratio_anualidad_credito',\n",
    "    'ratio_bienes_credito', 'ingreso_per_capita', 'credito_per_capita',\n",
    "    'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3',\n",
    "    'edad', 'años_empleado', 'dias_registro', 'dias_id_publicacion',\n",
    "    'CNT_CHILDREN', 'CNT_FAM_MEMBERS',\n",
    "    'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY',\n",
    "    'REG_REGION_NOT_LIVE_REGION', 'REG_CITY_NOT_WORK_CITY',\n",
    "    'ratio_edad_empleo', 'tiene_telefono', 'tiene_email', 'tiene_trabajo_telefono',\n",
    "    'inconsistencia_empleo_edad', 'inconsistencia_ingreso_alto'\n",
    "]\n",
    "\n",
    "variables_categoricas_cod = [f'{col}_cod' for col in variables_categoricas if f'{col}_cod' in df.columns]\n",
    "variables_finales = [v for v in variables_numericas if v in df.columns] + variables_categoricas_cod\n",
    "\n",
    "datos_modelo = df[variables_finales + ['TARGET', 'SK_ID_CURR']].copy()\n",
    "\n",
    "# Imputar nulos\n",
    "for col in variables_finales:\n",
    "    if datos_modelo[col].isnull().sum() > 0:\n",
    "        if col in ['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']:\n",
    "            datos_modelo[col].fillna(datos_modelo[col].median(), inplace=True)\n",
    "        else:\n",
    "            datos_modelo[col].fillna(0, inplace=True)\n",
    "\n",
    "print(f\"Variables finales: {len(variables_finales)}\")\n",
    "print(f\"Nulos restantes: {datos_modelo[variables_finales].isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 5: PREPARAR DATOS Y NORMALIZAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparación de datos completada\n",
      "Total muestras: 50,000\n",
      "Train: 35,000 | Test: 15,000\n",
      "Features: 37\n"
     ]
    }
   ],
   "source": [
    "X = datos_modelo[variables_finales].values\n",
    "y = datos_modelo['TARGET'].values\n",
    "ids = datos_modelo['SK_ID_CURR'].values\n",
    "\n",
    "# Normalizar con RobustScaler (mejor con outliers)\n",
    "escalador = RobustScaler()\n",
    "X_escalado = escalador.fit_transform(X)\n",
    "\n",
    "# Separar para entrenamiento de modelos no supervisados\n",
    "X_normales = X_escalado[y == 0]\n",
    "y_normales = y[y == 0]\n",
    "\n",
    "# Split para validación\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_escalado, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Preparación de datos completada\")\n",
    "print(f\"Total muestras: {len(X_escalado):,}\")\n",
    "print(f\"Train: {len(X_train):,} | Test: {len(X_test):,}\")\n",
    "print(f\"Features: {X_escalado.shape[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
